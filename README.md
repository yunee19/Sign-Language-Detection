# Sign-Language-Detection üåû
## Introduction to Sign Language Detection Program 

Sign Language Detection is a program designed to analyze and subsequently translate sign language, enabling users to communicate easily with others through expressive gestures and communication. This program brings numerous values and significances in developing practical products for the deaf and hard of hearing. Here are several key points:

1. **Effective Communication:** Sign Language Detection helps users of sign language interact more effectively, reducing communication barriers between them and those unfamiliar with the language.

2. **Development of Useful Products:** This program can be integrated into various applications and devices to create practical products, such as mobile apps, wearable devices, or other assistive tools.

3. **Creating Real-Time Communication Opportunities:** Sign Language Detection can provide real-time communication abilities, allowing the deaf and hard of hearing to confidently participate in conversations and interactions.

4. **Education and Learning:** The program can serve as an educational tool to help learners of sign language understand and practice gestures.

5. **Feedback and Flexibility:** Sign Language Detection can provide real-time feedback on the accuracy of gestures, assisting users in improving their skills and enhancing flexibility in interactions.

6. **Emergency Situation Support:** In emergency situations, individuals with hearing impairments can use Sign Language Detection to convey messages quickly and effectively.

7. **Enhancing Diversity and Acceptance:** By supporting communication within the deaf community, this program contributes to enhancing diversity and fostering acceptance in society.

In summary, Sign Language Detection is not just a communication support tool; it is a vital tool for creating practical solutions, contributing to improving the quality of life for the deaf and hard of hearing.

<hr>

**THE DESIRED OUTCOME:**
<hr>

![IMG](https://github.com/yunee19/Sign-Language-Detection/assets/133479803/35a9190b-883c-4252-881c-dca161a0be4d)


<hr>

**TO DO LIST:**
- Cloning Baseline Code 
- Collecting Images using OpenCV
- Labelling Images for Object Detection
- Training the Model
- Making Real Time Detections

**THE ACTUAL WORK**


### Step 1: Create Necessary Files and Folders

Before running the program, you need to establish the required folder structure. This structure consists of a root folder (e.g., "data") with subfolders for each label.

### Step 2: Image Collection

![quantrong1]Done
![pypoanh2](https://github.com/yunee19/Sign-Language-Detection/assets/133479803/a9bbb9ae-0451-48d4-be7a-fe2de8b3a49e)

‚ùå Training the Model

‚ùå Making Real Time Detections

## References
AUTHOR: Nicholas Renotte 

The video :[Sign Language Detection ](https://www.youtube.com/live/V0Pk_dPU2lY?si=AS2qrB97H2yDQN-v)

Original works : 
[Real Time Object Detection Code](https://github.com/nicknochnack/RealTimeObjectDetection),
[Image Collection Code](https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS/blob/main/Image%20Collection.ipynb) ,[LabelImg](https://github.com/HumanSignal/labelImg)
